{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04a6c687-811d-4f13-95a3-e2c874f2df73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape real text from a webpage and analyze sentiment\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, SpatialDropout1D, BatchNormalization, Bidirectional, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69876ef6-00a6-4701-9939-59c8037c8486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_text(url):\n",
    "    try: \n",
    "        response = requests.get(url, timeout = 10)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        # Remove unwanted script and style tags \n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.decompose()\n",
    "        # Extract visible text and clean whitespace\n",
    "        text = soup.get_text()\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split(\" \"))\n",
    "        text = ' '.join(chunk for chunk in chunks if chunk)\n",
    "        #return first 500 characters for demo \n",
    "        return text[:500]\n",
    "    except Exception as e:\n",
    "        return f\"Error scraping : {str(e)}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41b3762d-bcb7-4d02-adff-e32b2a4819d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_text= scrape_text(\"https://status.net/articles/examples-performance-reviews-good-satisfactory-poor/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb7eaa5-ad5e-407f-b532-a478350baba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ee576ce-1ec9-4de6-9df6-c16ca7ee0e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"This product is amazing! Highly recommend\",\n",
    "    \"Worst purchase ever. Complete waste of money\",\n",
    "    \"It's okay, nothing special but works fine\",\n",
    "    \"Absolutely love it! Best quality\",\n",
    "    \"Terrible experience. Very disappointed\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05fa385d-85c3-4e59-8097-766ef464925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = [1,0,1,1,0]\n",
    "# Labels : 1 = positive, 0 = negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d9f378a-e3b2-4c25-9017-7530ebdfe94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT PREPROCESSING FOR LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "872c182f-2df9-447c-93b6-1f5bf83c6f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 500 # Only keep 500 most frequent words\n",
    "max_len = 20 # Limit each review to 20 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f2b9140-53f9-4096-a317-bba5cae01119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text convert words - integer\n",
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16f7c2f8-9d83-49d7-a2f9-ada8178d5431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentences to padded sequences \n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "X = pad_sequences(sequences, maxlen = max_len)\n",
    "y = np.array(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4801e456-67cc-441f-adf9-ca0e745b2bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential([\n",
    "    Embedding(max_words, 128, input_length=max_len),    # Higher embedding dimension\n",
    "    SpatialDropout1D(0.3),                              # Drops entire word embeddings to improve robustness\n",
    "    Bidirectional(LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)),\n",
    "    BatchNormalization(),                               # Normalizes activations to speed up learning\n",
    "    LSTM(64, dropout=0.3, recurrent_dropout=0.3),       # Second LSTM layer for deeper temporal learning\n",
    "    Dense(64, activation='relu', kernel_regularizer='l2'),\n",
    "    Dropout(0.4),\n",
    "    Dense(32, activation='relu', kernel_regularizer='l2'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')                      # Binary classification output\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abf577f4-e6d8-4c0f-a594-afc3f1ad90c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "701319e0-77a8-4dda-b650-fc33ffe7edec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.6487 - val_accuracy: 0.0000e+00 - val_loss: 1.7228\n",
      "Epoch 2/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5000 - loss: 1.5771 - val_accuracy: 0.0000e+00 - val_loss: 1.7158\n",
      "Epoch 3/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.5193 - val_accuracy: 0.0000e+00 - val_loss: 1.7071\n",
      "Epoch 4/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5000 - loss: 1.7790 - val_accuracy: 0.0000e+00 - val_loss: 1.7016\n",
      "Epoch 5/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8333 - loss: 1.5386 - val_accuracy: 0.0000e+00 - val_loss: 1.6995\n",
      "Epoch 6/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 1.8779 - val_accuracy: 0.0000e+00 - val_loss: 1.6940\n",
      "Epoch 7/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6667 - loss: 1.5371 - val_accuracy: 0.0000e+00 - val_loss: 1.6897\n",
      "Epoch 8/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6667 - loss: 1.6441 - val_accuracy: 0.0000e+00 - val_loss: 1.6840\n",
      "Epoch 9/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6667 - loss: 1.5680 - val_accuracy: 0.0000e+00 - val_loss: 1.6791\n",
      "Epoch 10/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8333 - loss: 1.3666 - val_accuracy: 0.0000e+00 - val_loss: 1.6748\n",
      "Epoch 11/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6667 - loss: 1.3643 - val_accuracy: 0.0000e+00 - val_loss: 1.6693\n",
      "Epoch 12/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8333 - loss: 1.2170 - val_accuracy: 0.0000e+00 - val_loss: 1.6658\n",
      "Epoch 13/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 0.8333 - loss: 1.3873 - val_accuracy: 0.0000e+00 - val_loss: 1.6636\n",
      "Epoch 14/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.6667 - loss: 1.4332 - val_accuracy: 0.0000e+00 - val_loss: 1.6618\n",
      "Epoch 15/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.3076 - val_accuracy: 0.0000e+00 - val_loss: 1.6614\n",
      "Epoch 16/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6667 - loss: 1.4377 - val_accuracy: 0.0000e+00 - val_loss: 1.6607\n",
      "Epoch 17/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 1.1381 - val_accuracy: 0.0000e+00 - val_loss: 1.6603\n",
      "Epoch 18/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8333 - loss: 1.1838 - val_accuracy: 0.0000e+00 - val_loss: 1.6609\n",
      "Epoch 19/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.1521 - val_accuracy: 0.0000e+00 - val_loss: 1.6610\n",
      "Epoch 20/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.0293 - val_accuracy: 0.0000e+00 - val_loss: 1.6623\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE MODEL \n",
    "history1 = model1.fit(X, y, epochs = 20, \n",
    "         batch_size = 2, # number of samples processed before the model updates, \n",
    "         validation_split = 0.2, # use 20% of training for validation\n",
    "         verbose =1 # show progress during training)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d57904e0-633f-4662-8a7c-e9fa8f3d806e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMERS (PRETRAINED )\n",
    "transformer_sentiment = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34593fec-86fa-4fe8-b013-3bfc0552227a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lstm_model = Sequential([\n",
    "    Embedding(max_words, 16, input_length=max_len),\n",
    "    LSTM(32),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54840b0c-58da-4987-a41c-ed8843b28886",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a38040-0c0e-4b8e-b092-c837eb056273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e8e3d2d-2155-4c5b-97f4-5bb61e7209a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM PREDICTION \n",
    "test_seq = tokenizer.texts_to_sequences([scraped_text])\n",
    "test_pad = pad_sequences(test_seq, maxlen = max_len)\n",
    "lstm_pred = lstm_model.predict(test_pad, verbose = 0\n",
    "                          )\n",
    "lstm_sentiment = \"Positive\" if lstm_pred[0] > 0.5 else \"Negative\"\n",
    "lstm_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1343d742-6abf-44db-ad86-d0f40af4e508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LSTM Sentiment -> Negative (0.50)\n"
     ]
    }
   ],
   "source": [
    "transformer_result = transformer_sentiment(scraped_text[:512])[0]\n",
    "print(f\" LSTM Sentiment -> {lstm_sentiment} ({lstm_pred[0][0]:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80f16da3-89f3-4e6b-baf9-09d42f462372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Transformer Sentiment → POSITIVE (0.98)\n"
     ]
    }
   ],
   "source": [
    "print(f\"  Transformer Sentiment → {transformer_result['label']} ({transformer_result['score']:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b29ddb7b-9e38-48ba-94ef-a0c2e35086ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_reviews = [\n",
    "    \"Great product, works perfectly!\",\n",
    "    \"Overall no complaints, decent for the price.\",\n",
    "    \"Absolutely fantastic! I loved the design and performance.\",\n",
    "    \"Disappointed with the quality, expected much better.\",\n",
    "    \"Terrible customer service, won’t buy again.\",\n",
    "    \"It's okay, does the job but nothing special.\",\n",
    "    \"Very easy to use and setup, highly recommend!\",\n",
    "    \"Not worth the money, broke after a week.\",\n",
    "    \"Quality is average, but delivery was fast.\",\n",
    "    \"Excellent value for money. Will purchase again!\",\n",
    "    \"Horrible experience. The item arrived damaged.\",\n",
    "    \"Amazing sound quality and comfortable fit.\",\n",
    "    \"Mediocre at best, I’ve used better alternatives.\",\n",
    "    \"Loved it! Exceeded my expectations.\",\n",
    "    \"It stopped working after a few days — waste of money.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4afb0d82-d577-49bc-af12-82b3c04ceecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Review: Great product, works perfectly!\n",
      "LSTM Negative (0.50)\n",
      "Transformer POSITIVE ( 1.00)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Review: Overall no complaints, decent for the price.\n",
      "LSTM Positive (0.50)\n",
      "Transformer POSITIVE ( 0.98)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Review: Absolutely fantastic! I loved the design and performance.\n",
      "LSTM Positive (0.50)\n",
      "Transformer POSITIVE ( 1.00)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Review: Disappointed with the quality, expected much better.\n",
      "LSTM Negative (0.50)\n",
      "Transformer NEGATIVE ( 1.00)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Review: Terrible customer service, won’t buy again.\n",
      "LSTM Positive (0.50)\n",
      "Transformer NEGATIVE ( 1.00)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Review: It's okay, does the job but nothing special.\n",
      "LSTM Positive (0.50)\n",
      "Transformer NEGATIVE ( 0.99)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Review: Very easy to use and setup, highly recommend!\n",
      "LSTM Positive (0.50)\n",
      "Transformer POSITIVE ( 1.00)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Review: Not worth the money, broke after a week.\n",
      "LSTM Positive (0.50)\n",
      "Transformer NEGATIVE ( 1.00)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Review: Quality is average, but delivery was fast.\n",
      "LSTM Negative (0.50)\n",
      "Transformer POSITIVE ( 0.99)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Review: Excellent value for money. Will purchase again!\n",
      "LSTM Positive (0.50)\n",
      "Transformer POSITIVE ( 1.00)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Review: Horrible experience. The item arrived damaged.\n",
      "LSTM Positive (0.50)\n",
      "Transformer NEGATIVE ( 1.00)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Review: Amazing sound quality and comfortable fit.\n",
      "LSTM Positive (0.50)\n",
      "Transformer POSITIVE ( 1.00)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Review: Mediocre at best, I’ve used better alternatives.\n",
      "LSTM Positive (0.50)\n",
      "Transformer NEGATIVE ( 1.00)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Review: Loved it! Exceeded my expectations.\n",
      "LSTM Positive (0.50)\n",
      "Transformer POSITIVE ( 1.00)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Review: It stopped working after a few days — waste of money.\n",
      "LSTM Negative (0.50)\n",
      "Transformer NEGATIVE ( 1.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for review in sample_reviews: \n",
    "    seq= tokenizer.texts_to_sequences([review])\n",
    "    pad = pad_sequences(seq, maxlen = max_len)\n",
    "    lstm_p = lstm_model.predict(pad, verbose = 1)[0][0]\n",
    "    trans_p = transformer_sentiment(review)[0]\n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"LSTM {'Positive' if lstm_p > 0.5 else 'Negative'} ({lstm_p:.2f})\")\n",
    "    print(f\"Transformer {trans_p['label']} ({trans_p['score']: .2f})\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
